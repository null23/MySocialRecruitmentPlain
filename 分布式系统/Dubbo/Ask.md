## Dubbo流程
首先得有一个服务消费者 跟 服务提供者，都用接口的方式进行调用。 还有我们之前说过分布式系统都有一个服务注册中心。所以这里还得有一个服务注册中心。 
接下来，当我们的服务启动以后，会先向服务注册中心进行注册，服务注册中心会记录服务提供者 的信息。
服务消费者回去服务注册中心去拉取服务提供者列表，这就是一个服务注册跟服务发现的过程。 
发起服务调用之前会创建一个 动态代理对象 ，在我们的消费者中只有一个接口，我们可以认为动态代理相当于给这个接口动态的创建了一个实现类出来。
然后用动态代理对象进行接口调用。demoservice.sayhello(“hello”) 其实就是在调用动态代理对象 。 
我们的服务提供者会有多台机器，到底我们要去调用那一台机器呢？怎么选择呢？ 此时动态代理对象会去找一个 Cluster 这一层的东西。
这一层就负责来找具体要调用那一台机器。 那么 Cluster 就得感知到服务的机器列表。 Cluster 里面有很多组件，比如 Directory、Router 还有LoadBalance 。 此时会使用 负载均衡组件 LoadBalance 挑选一台机器。 
好啦，我们找到机器了，比如我们要去调用 DemoService 里面的 sayHello 接口，那么，我们去调用这个接口，我们需要使用什么协议呢？我们的请求是按照什么样的形式组织起来发送过去的呢？ 
比如 http 协议 就是这种 /demoService/sayHello?name=zhoq， 再比如 dubbo 协议，可能就是 interfance=demoService|method=sayHello|params=name:zhouq。 现在协议选好了，然后就会走 Exchange 这层，这层就是来包装我们用选好的协议组织起来的请求数据，包装成 Request 。
现在我们挑选好了机器，也把请求按照协议进行组织好了，并且封装好了请求。那么这个请求怎么发送到服务提供者的哪台机器呢？ 
此时我们就需要选择一个网络通信的框架。由他来负责把你的请求通过网络发送过去，在发送过去之前，还得对请求进行序列化。 
那服务提供者怎么才能收到这个请求呢？ 此时服务提供者里面也得需要一个网络通信框架，他去监听你开发放的某个端口，比如 就启动一个 netty 去监听消费者发送过来的请求。 
接受到请求过后，然后进行反序列化，然后，前面我们发过来的是 通过 Exchange 层包装的 Request 请求，那么这里也需要 这层来对 请求进行解析。解析的时候，也需要根据一种协议来进行解析。 
实际上 解析完成请求以后，还会创建一个 动态代理对象，再去调用我们的服务提供者接口。

## 作业1 自己画出RPC框架设计图！   
## 作业2 不看资料，自己手画Spring Cloud底层原理图

优秀作业，学员：顾飞点评：思考的非常深入，技术选型有自己的见解
作业1： 
1、动态代理层：RPC框架的一切调用细节都是动态代理方法里实现的。可选用Java原生Proxy类方法或Spring的Cglib实现。生成接口类的代理类，重写方法，实现真实调用。 

2、注册中心：提供者启动时进行注册，消费者对某些服务进行订阅，服务发现。
 ① zookeeper， dubbo service-A service-B provider cosumer provider consumer IP+port IP+port IP+port IP+port IP+port IP+port IP+port IP+port 如上图设计好的树状结构来存储
Providers启动时在Zookeeper中某个服务节点下创建临时子节点，节点名称使用IP、端口、权重等信息拼接字符串，这样实现服务注册。
Consumer监听某个服务节点服务的子节点，并且拉取子节点列表。实现服务订阅和发现。
当Provider上线或下线时，临时节点发生新增或删除。所以Consumer那边监听会收到通知，拉取最新的注册表数据，更新本地注册表缓存，这样实现服务发现。 
② 也可以采用Eureka的实现方式，采用纯内存ConcurrentHashMap来存储注册表，Provider启动时将IP、端口、权重等信息注册。实现服务注册。
Consumers定时去拉取注册表缓存在本地。实现服务发现。然后各服务采用定时心跳的方式来告诉注册中心自己是否存活。 实现故障感知。 
比如用Map<String,Map<String,Lease<InstanceInfo>>>这样的结构来保存，服务名为key，Value Map的key为实例ID，Lease中维护最近的心跳时间，InstanceInfo中保存实例的IP、端口等信息。这是内存注册表。 
并且可以加入多级缓存来优化并发读写冲突。 配置好合适的注册表拉取时间和心跳时间，比如30秒，则可以单机承载大规模系统日千万级的访问量。 
综上：Zookeeper方式显然更加实时感知集群变动。而Eureka的方式因为是定时拉取，所以消费端对集群变更感知会有一定延时性。

3、Cluster层：实现路由和负载均衡、集群事件处理，比如故障切换等。必备轮询、加权轮询、随机、加权随机、一致性Hash等路由或负载均衡方式。 
加权可以根据权重增加虚拟节点实现。一致性Hash，采用Hash环方式，并加入一定数量的虚拟节点来使节点更加均衡的分布在Hash环上，顺时针旋转时，继而请求分布更加均匀。可以采用ConcurrentSkipListMap来实现。 

4、数据发送部分：Exchange，Portocol、序列化反序列化机制、Transport网络IO。 Exchange封装为Request/Response，结合BlockingQueue将Netty异步通信转化同步。 
协议可以是HTTP、dubbo等 序列化加入多种选择，比如Json、Protobuf、Protostuff、Hessian、Kryo等、Java序列化等等。 

5、网络IO部分，可以使用BIO、NIO。BIO性能极差！推荐使用NIO框架Netty来实现，并处理好数据粘包问题。 
使用多路复用IO机制，服务端有一组Acceptor线程，ServerSocketChannel监听某个端口，而Acceptor线程通过多路复用器Selector来轮询监听ServerSocketChannel的Accept事件。
当客户端的netty请求连接时，此时会创建对应的SocketChannel。被Processor线程组通过Selector轮询监听，来处理实际的IO。
当客户端发来数据时，服务端SocketChannel触发事件，由Processor线程去解析请求，经历反序列化和Exchange、Protocol层层解析后，经由代理类找到对应的服务实现方法处理。再经过SocketChannel返回给客户端。 
客户端同样是processor线程组监听到SocketChannel的事件，读取响应给程序。 

综上所述： 划分层次的话，就是10层 Service、Config、Proxy、Registry、Cluster、Protocol、Exchage、Transport、Serialize、Monitor

## 自己设计一个RPC
老师好，我说下我自己设计RPC框架的话，大体的思路： 

1、框架讲究能够配置的都提取为配置，然后框架再根据配置去自动做很多事情，先说配置，配置可以选择在xml中配置，或者提供元数据注解的方式。在这里，RPC框架的话，主要是配置我们要调用的接口，接口的方法。 

2、在真正要进行调用的时候（或者是程序启动时），此时需要生成RPC接口的动态代理，由于是对接口生成代理，直接使用jdk的动态代理即可，动态代理中，即是我们的核心逻辑； 

3、传给动态代理的参数，包括了要调用的接口、接口的方法、以及参数，我们就可以根据接口名，去服务注册表拉取服务注册数据，拉到的数据可能是一个list，里面保护了实现了该接口的服务的ip、端口等； 

4、拿到的是列表，但我们只需要调用其中一台，这里需要进行负载均衡，如果简单实现，可以直接轮询，要做成动态扩展的话，考虑SPI机制
即由我们作为框架作者，指定负载均衡的接口，框架使用者可以实现我们的接口，并像SPI机制一样，在META-INF目录下的文件中指定接口的实现
我们框架可以自动扫描类路径下的这类文件，如果发现框架使用者自定义了实现，即使用，否则使用框架默认的； 

5、在第四步中，获取到一台服务器后，开始构造请求，然后丢给下一步； 

6、网络通信层，这一层需要进行对要发送的请求，进行编码，编好后交给网络通信框架发送出去，可以选择使用netty等成熟框架；
这一层层次不是特别清晰，因为如果使用netty的话，编解码部分一般会直接使用netty的encoder，并在pipeline中直接发送出去。 
这里需要考虑的是，是否要考虑长连接，如果使用长连接的话，应该需要设计连接池，避免每次RPC调用时，都重建连接，最好直接从连接池获取。 
还要考虑的是，像netty是nio读写，写操作不会阻塞，但是我们还需要等待rpc调用返回，才能将结果返回上层。 这一步的设计，还需要参考各netty客户端框架的实现。 

7、收到rpc响应后，返回给上层等。 
有个问题想咨询老师：客户端采用netty实现的框架，在业务线程等待服务端返回时，线程此时不能返回给上层，因为数据还没回来
那么此时，业务线程是要阻塞吗？一般数据回来是在io线程，io线程再去notify业务线程？

这块比较困惑，希望老师解答一下

问题解答：
是的，dubbo是通过类似Future.get()方法来实现阻塞的，底层是通过ReentrantLock的Condition的await()和notify来实现阻塞和唤醒的。