由于Kafka的机制，就是多个consumer消费多个partition的数据，数据分发到哪个partition是不能确定的。
**所以首先，如果要保证顺序性，那就得只能用一个topic，一个partition，一个consumer。**
但是即使是消费一个partition的时候，考虑到单线程吞吐量不大，我们就得开多个线程去消费，多线程消费同一个partition的数据的顺序性也是没办法确定的，比如开三个线程Thread1，Thread2，Thread3，然后读取partition的三条数据 数据1，数据2，数据3 然后把这三条数据插入到数据库里，这里我们没办法保证插入的顺序性。

如何保证插入的顺序性呢？我们没办法在多线程同时插入DB的场景下保证顺序性。
所以我们可以把这三条的插入用一个线程去做。
**方案就是用三个内存队列(对应三个线程)，让每个线程只消费一个对应的一个内存队列，也就是说我们把数据1，数据2，数据3 都放到内存队列A中，让一个线程从内存队列A中读取值，这样肯定就可以保证顺序性。**
那么怎么维护这个内存队列呢？可以用业务主键，比如订单id，根据hash值计算，分发到这三个不同的内存队列中。