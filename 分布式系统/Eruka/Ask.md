# 请问readwriteCache有啥用，感觉只用一个readonlyCache从实现上到性能上都满足，没太理解用readwriteCache好在哪里？
eureka里面readwritemap采用的guava的缓存，内部有个load监听你的Key，你不需要关心Key，如果有服务进行下线或者注册，会去根据key的类型，名称来去判断是增量抓取还是全量抓取数据。
针对readonlymap，默认是开启的，你可以进行设置关闭。
不直接操作eureka server端的本地缓存。

这个多级缓存的方案，为的就是解决，锁冲突，因为如果你的机器如果不断在注册，那么你的register会不断被写入，而且加的是读写锁，一旦有人去读它，那么读写互斥，而且读锁是不会排斥读的，那么你大量的写入，会导致服务注册不上去，卡死，这是考虑的极端场景，在一点你加锁本身就是一个很重的过程，eureka本身设计就是ap，为了保证最终一致性，在每次拉取数据会去跟自己本地的缓存进行对比hash，如果不一致，怎么办？重新拉取缓存数据。
concurrenthashmap是减少了对于锁的争用，但是你考虑一下，同一时间，你还要去注册很多到register，这时候你考虑的问题，难道每次只是依靠concurrenthashmap去保证？这个又问题的，问题的原因在于，如果多个线程同时都是一个hashcode，那么你的链表挂载会有多么剧烈，在下一次table扩容，全部进行重新hashcode落入链表中，这也是一个极端考虑，还有别人还在加了读写锁，对于服务心跳机制还加入了sync，你怎么考虑。而且在计数器还是atomic系列，还是cas无锁化。这些你结合一下。
多级缓存就是为了解决，读写互斥，减少锁的争用。就算你是concurrenthashmap又怎么样，为何别人还需要加个读写锁，考虑一下这个问题。

本地缓存的注册表采用applications封装的，其实读取还是读的register，
最后一层是本地缓存数据，因为三层队列，第一层readonlymap是可以使用或者不使用的，有task回去过气这个缓存，而且writemap层面也有定时过期的概念，但是内部的load回去监听每次下线的key，进行拉取本地注册表信息。

# 而且，你们考虑过一点没有，服务之间如何进行通信，采用什么方式去同步集群的注册表信息。
是不是采用一个异步队列？然后每次注册表有变化，封装成一个task，丢到这个队列里面，队列另外一头有个消费者拿到task就去发给其他集群机器。
每次集群同步只有一次batch操作，减少了网络io，针对zk，每次服务注册需要m-s进行通信，那么代价就很大了。延伸到es的集群，写入数据只有在primary shard和replica shard全部完成才会告诉你这个数据是写入完整的，不过es可以动态调整你的shard。

# 如果一个服务实例宕机了，eureka server要 过180s才能感知到？
不是，30s对于client回去抓取增量的queue信息，对比hash，如果不一致会去进行抓取全量注册表信息。